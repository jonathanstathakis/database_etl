{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: creating excluded list for outliers\n",
    "description: 'while observing outliers it was deemed prudent to create a list of runs to be excluded from the core dataset during development, while retaining them for perhaps later reclaimation. To this end a `excluded` table was created, and a `inc_` `chm` and `img_stats` tbls were created as the subset of the respective master tables without the excluded runs.'\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import duckdb as db\n",
    "import polars as pl\n",
    "from database_etl.definitions import DB_PATH, RAW_DATA_LIB\n",
    "\n",
    "pl.Config.set_fmt_str_lengths(9999)\n",
    "pl.Config.set_tbl_rows(9999)\n",
    "con = db.connect(DB_PATH)\n",
    "\n",
    "image_files = list(RAW_DATA_LIB.glob(\"*.D/extract_*/data.parquet\"))\n",
    "len(image_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"--sql\n",
    "show tables\n",
    "\"\"\"\n",
    ").pl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"--sql\n",
    "select * from image_stats limit 5\n",
    "\"\"\"\n",
    ").pl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"--sql\n",
    "select distinct mins_max from image_stats\n",
    "\"\"\"\n",
    ").pl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_time_outliers(con: db.DuckDBPyConnection, time_cutoff: float) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    return a pl df containing samples whose right side of time dim interval is less\n",
    "    than `time_cutoff`\n",
    "    \"\"\"\n",
    "    return con.execute(\n",
    "        \"\"\"--sql\n",
    "    select\n",
    "        *\n",
    "    from\n",
    "        image_stats\n",
    "    join\n",
    "        chm\n",
    "    on\n",
    "        image_stats.pk = chm.pk\n",
    "    where\n",
    "        mins_max < ?\n",
    "    \"\"\",\n",
    "        parameters=[time_cutoff],\n",
    "    ).pl()\n",
    "\n",
    "\n",
    "find_time_outliers(con=con, time_cutoff=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Excluded Table and Adding Sample 20.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_excluded_tbl(con: db.DuckDBPyConnection) -> None:\n",
    "    con.sql(\n",
    "        \"\"\"--sql\n",
    "    create or replace table excluded (\n",
    "        pk integer primary key references chm(pk),\n",
    "        runid varchar unique not null,\n",
    "        reason varchar not null\n",
    "    );\n",
    "    \"\"\"\n",
    "    ).pl()\n",
    "\n",
    "\n",
    "def add_61_to_excluded(con: db.DuckDBPyConnection) -> None:\n",
    "    \"\"\"\n",
    "    As shown in `find_time_outliers`, sample `pk` = 61 is an aborted run with a runtime\n",
    "    of 14 seconds, and is to be added to the excluded list.\n",
    "    \"\"\"\n",
    "    con.sql(\n",
    "        \"\"\"--sql\n",
    "        insert into excluded\n",
    "            select\n",
    "                pk,\n",
    "                runid,\n",
    "                'aborted run' as reason\n",
    "            from\n",
    "                chm\n",
    "            where\n",
    "                pk = 61;\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "def create_inc_chm_view(con: db.DuckDBPyConnection) -> None:\n",
    "    \"\"\"\n",
    "    creates a view consisting of the anti join of chm and excluded, resulting in the set\n",
    "    of runs deemed includable in downstream analyses.\n",
    "    \"\"\"\n",
    "    con.sql(\"\"\"--sql\n",
    "    create or replace view inc_chm as\n",
    "        select\n",
    "            *\n",
    "        from\n",
    "            chm\n",
    "        anti join\n",
    "            excluded\n",
    "        on\n",
    "            excluded.pk = chm.pk;\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "create_excluded_tbl(con=con)\n",
    "add_61_to_excluded(con=con)\n",
    "create_inc_chm_view(con=con)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"--sql\n",
    "describe excluded\n",
    "\"\"\"\n",
    ").pl()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Included Image Stats (`inc_img_stats`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inc_img_stats(con=con) -> None:\n",
    "    \"\"\"\n",
    "    masks `image_stats` by the difference from the `excluded` list, returning the runs\n",
    "    which are included.\n",
    "    \"\"\"\n",
    "    con.sql(\n",
    "        \"\"\"--sql\n",
    "    create or replace view inc_img_stats as\n",
    "        select\n",
    "            *\n",
    "        from\n",
    "            image_stats ist\n",
    "        anti join\n",
    "            excluded exc\n",
    "        on\n",
    "            ist.pk = exc.pk;\n",
    "    \"\"\"\n",
    "    ).pl()\n",
    "\n",
    "\n",
    "create_inc_img_stats(con=con)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con.sql(\n",
    "#     \"\"\"--sql\n",
    "# select\n",
    "#     distinct mins_max\n",
    "# from\n",
    "#     inc_img_stats\n",
    "# \"\"\"\n",
    "# ).pl().pipe(display)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"--sql\n",
    "describe inc_img_stats\n",
    "\"\"\"\n",
    ").pl()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So when accounting for the aborted run pk = 61, all runs have the same end time - 52 mins, until the 3rd significant figure. Considering that it is one observation every 0.4 seconds, then only the first two significant figures are relevent, and thus they are the same. I presume that rounding to the second signifiant figure will make all time labels the same - this is easier than resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = con.sql(\n",
    "    \"\"\"--sql\n",
    "select\n",
    "    path\n",
    "from\n",
    "    inc_img_stats\n",
    "\"\"\"\n",
    ").fetchall()\n",
    "\n",
    "paths[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(paths[0][0])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_parquet(\n",
    "    \"/Users/jonathan/mres_thesis/database_etl/database_etl/data/raw_uv/114.D/extract_2024-09-18T212559/data.parquet\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(paths[0][0])\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "database-etl-SYkgHnDq-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
